# Сравнение графовых RAG в чат-ботах

## Введение

### О чём статья и зачем

Всем привет! Мы — группа начинающих ML-специалистов в X5 Tech в команде чат-ботов. В этой статье мы расскажем о state-of-the-art подходах использующих графы знаний в RAG (Retrieval-Augmented Generation) и сравним три алгоритма: **FastRAG**, **LightRAG** и **MiniRAG**. Также исследуем, как эти методы показывают себя в сравнении с классическим RAG в обработке баз знаний и поиска релевантной информации.

### Что такое RAG

**RAG** — это гибридная архитектура, сочетающая поиск информации и генерацию текста через LLM. Классический RAG использует лексический или семантический поиск по текстовым фрагментам в базе знаний. Затем найденная информация и запрос подаются в LLM, чтобы она, используя необходимую информацию, ответила на запрос. Подробнее можно почитать [здесь](https://habr.com/ru/articles/779526/).  

![RAG иллюстрация](rag_image.png)  

### Зачем нужен графовый RAG

К сожалению, обычный RAG не лишён недостатков:  
1. Ограниченная семантическая интеграция: Извлечение информации происходит без учета междокументных и внутридокументных связей. 
2. LLM не понимает полного контекста, так как берётся только часть исходных данных.  
3. При увеличении количества данных ухудшается качество поиска.
4. Отсутствие структурированных связей: Стандартный RAG не моделирует отношения между сущностями в данных.

RAG, основанный на графе знаний, способен полностью или частично решить данные недостатки.

### Что такое граф знаний

**Граф знаний** — это структура данных, где:  
- **Узлы** — сущности (например, `ПОКУПАТЕЛЬ`, `ДИРЕКТОР`) или целый документ.  
- **Рёбра** — связи между ними (например, *«регулируется»*, *«влияет на»*).  

В отличие от обычного векторного поиска, графы сохраняют семантические отношения. Это позволяет связывать информацию из различных документов и отвечать на более сложные вопросы.  

![Граф знаний](knowledge_graph_image.png)  

### Использование графа знаний

Графовые RAG имеют схожую структуру с обычным алгоритмом, но вносят изменения в некоторые шаги:  

1. **Индексация**: из документов извлекаются сущности и связи (через LLM), формируя граф.  
2. **Поиск**: вместо векторного сравнения фрагментов система обходит граф, находя связанные сущности и контексты.  
3. **Генерация**: LLM получает не только текстовые фрагменты, но и пути из графа, что улучшает связность ответов.  
