# Сравнение графовых RAG в чат-ботах

## Введение

### О чём статья и зачем

Всем привет! Мы — группа начинающих ML-специалистов в X5 Tech. Наша команда занимается разработкой чат-ботов, которые дают ответы на вопросы, основываясь на предоставленной базе знаний. Это наша первая статья на Хабре, и в ней мы хотим рассказать о сравнении трёх графовых подходов к RAG (Retrieval-Augmented Generation): **FastRAG**, **LightRAG** и **MiniRAG**. Мы исследовали, как эти методы показывают себя по сравнению с классическим RAG в обработке различных баз знаний и поиска нужной информации.

### Что такое RAG

**RAG** — это гибридная архитектура, сочетающая поиск информации (*retrieval*) и генерацию текста (*generation*) через LLM. Классический RAG использует лексический или семантический поиск по текстовым фрагментам (базе знаний). Затем найденная информация и запрос подаются в LLM, чтобы она суммаризировала, нашла необходимую информацию и ответила на запрос. Подробнее можно почитать [здесь](https://habr.com/ru/articles/779526/).  

![RAG иллюстрация](rag_image.png)  

### Зачем нужен GraphRAG

К сожалению, обычный RAG не лишён недостатков:  
1. Он не может связать информацию, разбросанную по различным документам.  
2. LLM не понимает полного контекста, так как берётся только часть исходных данных.  
3. При увеличении количества данных ухудшается качество поиска.  

Эти недостатки способен решить **GraphRAG** — RAG, основанный на графе знаний.

### Что такое граф знаний

**Граф знаний** — это структура данных, где:  
- **Узлы** — сущности (например, `ПОКУПАТЕЛЬ`, `ДИРЕКТОР`).  
- **Рёбра** — связи между ними (например, *«регулируется»*, *«влияет на»*).  

В отличие от обычного векторного поиска, графы сохраняют семантические отношения. Это позволяет связывать информацию из различных документов и отвечать на более сложные вопросы.  

![Граф знаний](knowledge_graph_image.png)  

### Построение графа знаний

Графовые RAG имеют схожую структуру с обычным алгоритмом, но вносят изменения в некоторые шаги:  

1. **Индексация**: из документов извлекаются сущности и связи (через LLM), формируя граф.  
2. **Поиск**: вместо векторного сравнения фрагментов система обходит граф, находя связанные сущности и контексты.  
3. **Генерация**: LLM получает не только текстовые фрагменты, но и пути из графа, что улучшает связность ответов.  
