# Название

## Введение
- О чём статья и зачем
- Что такое РАГ и какие проблемы мы хотим решить
- Что такое граф знаний
- Как они объединяются
- Референсы с конференций и новые статьи (это новый хайповый подход с более интуитивной идеей понимания наших данных)

Впервые идея использования графов знаний для RAG`ов была представлена в рамках Microsoft GraphRAG, опубликованного в начале 2024. На данный момент это направление активно развивается благодаря новым подходам предлагающим более интуитивное понимание контекста и state-of-the-art показатели на вопросно-ответных бенчмарках. 

## Теория
- Виды графовых РАГов
- GraphRAG Microsoft (откуда всё началось)
- Как добавлять новые документы вместо переиндексации = индексация наших алгоритмов

### Более продвинутые алгоритмы, которые мы пробовали

#### FastRAG

#### LightRAG

#### MiniRAG  
MiniRAG это модификация подхода LigthRAG, которая меньше использует LLM на этапе ретрива и делигирует составление контекста к запросу графовым алгоритмам. Авторы предлагают формулы для определения полезности сущностей, рёбер и путей графа для контекта. На основе данных показателей алгоритм находит в графе путь рассуждений, который наиболее логично соединяет вершины и ребра связанные с контекстом запроса.

##### Индексация

Процесс почти полностью повторяет индексацию LigthRAG

- С помощью one-shot промпта превращем каждый текстовый фрагмент в 2 таблицы
  - Информация о сущностях(Название, тип)
  - Информация о связях(смежные вершины, короткое описание, численная сила связи)  
``` json
("entity"{tuple_delimiter}СИСТЕМА ОПЛАТЫ ТРУДА{tuple_delimiter}объект{tuple_delimiter}Система оплаты труда для сотрудников администрации магазинов){record_delimiter})
("relationship"{tuple_delimiter}СИСТЕМА ОПЛАТЫ ТРУДА{tuple_delimiter}ДИРЕКТОР МАГАЗИНА{tuple_delimiter}Система оплаты труда определяет условия оплаты для директора магазина{tuple_delimiter}оплата труда{tuple_delimiter}5){record_delimiter}
```
- Дедуплицируем с уже находящимися в графе элементами и добавляем новые
- В отличнии от LigthRAG не извлекаем high и low-level keywords

##### Ретрив

Можно выделить 4 основных этапа

- **Нахождение релевантных к запросу сущности**  
  Для построения путей рассуждения нам понадобятся вершины из которых мы можем начать.  
  С помощью zero-shot промпта выделяем сущности в запросе пользователя и для каждой найденной сущности находим близжайшую вершину в графе используя эмбеддинги.  
  ![ретрив1](ретрив1.png)

- **Нахождение релевантных к ответу сущности**  
  При поиске семантически похожих фрагментов текста с использованием эмбеддингов и косинусного расстояния, в общем случае расстояние от запроса до похожего запроса будет меньше, чем расстояние от запроса до правильного документа, похожего по смыслу. Это связано с различиями в структуре запроса и документа, а также с их длиной.
  ``` python
  query = "Когда Карл Маркс начал писать Капитал?"
  query2 = "Как Капитал изменил жизнь Карла Маркса?"
  query2_answer = "Карл Маркс начал работать над своей знаменитой книгой 'Капитал' в 1857 году, и это стало центральным проектом его жизни. Несмотря на финансовые трудности и болезни, он упорно работал над трудом, который в конечном итоге значительно укрепил его репутацию как одного из ведущих теоретиков социализма. Первый том 'Капитала' был опубликован в 1867 году, но Маркс не успел закончить второго и третьего томов, которые были опубликованы уже после его смерти его другом и соратником Фридрихом Энгельсом. Эта работа не только изменила его личную жизнь, но и оказалась влиятельной для всего мирового социального и экономического движения."

  # Embed the texts
  emb_query = hf_embeddings.embed_query(query)
  emb_query2 = hf_embeddings.embed_query(query2)
  emb_query2_answer = hf_embeddings.embed_query(query2_answer)
  # Calculate cosine distances
  distance_query_query2 = cosine(emb_query, emb_query2)
  distance_query_query2_answer = cosine(emb_query, emb_query2_answer)
  # Print the distances
  print(f"Cosine distance between emb_query and emb_query2: {distance_query_query2}")
  print(f"Cosine distance between emb_query and emb_query2_answer: {distance_query_query2_answer}")

  >>>Cosine distance between emb_query and emb_query2: 0.0639
  >>>Cosine distance between emb_query and emb_query2_answer: 0.1163
  ```
  Поэтому, проводя поиск только на основе векторизированного запроса, мы рискуем упустить некоторые релевантные сущности.
  
  Для нахождения сущностей, релеватных именно к ответу, мы просим LLM определить релевантные типы сущностей и выделяем из общего графа подмножество подходящих вершин.  
  ![ретрив2](ретрив2.png) 
  Эти вершины будут конечными вершинами путей рассуждений.

- **Выделение релевантных ребер графа**  
  Мы уже нашли подмножества начальных и конечных вершин для путей рассуждений. Осталось найти промежуточные ребра для упрощения перебора возможных вариантов.  
  ![ретрив3](ретрив3.png)
  Отбираем ребра смежные к найденным вершинам. Сортируем их используя следующую формулу важности ребра
  ![edge_score](edge_scoring.png)
    ДОПИСАТЬ НОТАЦИИ

- **Построение пути расслеждений**  
  Теперь мы готовы провести логический путь от запроса к ответу по нашему графу. Перебираем пути длины n соединяющие вершины запроса с вершинами для ответа и сортируем их по количеству попавших в путь релевантных ребер и вершин.
  ![ретрив4](ретрив4.png)
  Ранжируем пути на основе следующей формулы
  ![path_score](path_scoring.png)
  Получив топ k лучших путей мы формируем контекст их их сущностей и привязанных к ним чанков.

## Результаты

- **Дизайн экспериментов**  
  Нашей основной задачей изначально было тестирование данных алгоритмов в домене X5  
  Мы проводили эксперименты на двух базах знаний чтобы узнать применимость алгоритмов к разным видам данным
  - ~500 рабочих инструкций  
    Бэйзлайн ретрива: RAG  
    Бейзлайн генераций: RAG + Reranker + Chaining
  - ~1500 записей форамата вопрос-ответ  
    Бэйзлайн ретрива: RAG + симметричный поиск
        
    
- Метрики
![метрики](метрики.png)
## Заключение
- Обоснованность использования в нашем домене
- Варианты улучшений
